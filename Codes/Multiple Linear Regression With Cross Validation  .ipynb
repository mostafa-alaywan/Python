{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Ames Housing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "from plotnine import *    # https://plotnine.readthedocs.io/en/stable/api.html#geoms\n",
    "%matplotlib inline \n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the url of the housing dataset :\n",
    "url = \"https://github.com/DrSaadLa/MLLabs/raw/main/data/housing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first five instances :\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first five instances:\n",
    "housing.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Dataset\n",
    "The dataset __housing__ contains :\n",
    "\n",
    "- 5000 instances (observations)\n",
    "\n",
    "- 6 quantitatives(numericals) variables\n",
    "\n",
    "- 1 categorical variables : Adresse\n",
    "\n",
    "- No Missing Values\n",
    "\n",
    "- No Duplicated Instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data information :\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking duplicated instances : \n",
    "housing.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run desriptive statistics for numerical variables :\n",
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the variable \"Address\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.drop('Address' , axis = 1 , inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename The  Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.rename(columns={'Avg. Area Income':'Area Income', 'Avg. Area House Age':'House Age', \n",
    "        'Avg. Area Number of Rooms':'Number of Rooms','Avg. Area Number of Bedrooms':'Number of Bedrooms'}\n",
    "               ,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapiro's Test on the target variable : Price "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The Shapiro-Wilk test tests the null hypothesis that the data was drawn from a normal distribution.**\n",
    "- **p_value = 0.95 > 0.05 we don't have enough evidence to reject the hypothesis of normality distribution of the price of houses** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary module to evaluate the Shapiro's Test \n",
    "from scipy import stats   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_test = stats.shapiro(housing['Price'])\n",
    "shapiro_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Histogram of Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(housing, aes(x='Price')) + geom_histogram(bins=20 , fill=\"red\" ,color = \"green\" ,  alpha = 0.75) +labs(title = \"Histogram Of Houses Prices\" ,x = \"Price\" , y = \"Frequency\"  ) + theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's Correlation Coefficents Between The Quantitative Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The linear relationship between the house price and the number of bedrooms is negligeable of 0.17**\n",
    "\n",
    "- **There is a weak positive linear relationship between the house price and the Avg. Area Number of Rooms of 0.34**\n",
    "\n",
    "- **There is a moderate positive linear relationship between the house price and Area Population of 0.41 and Avg. Area House Age of 0.45 and Avg. Area Income of 0.64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix : \n",
    "correlation_matrix = housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap :\n",
    "sns.heatmap(correlation_matrix , annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation pairplot :\n",
    "sns.pairplot(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features : \n",
    "X = housing[['Area Income', 'House Age', 'Number of Rooms', 'Number of Bedrooms',\n",
    "       'Area Population']]\n",
    "\n",
    "# Target : \n",
    "y= housing['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data , Training  and Assessment The Model With Different Seeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split               # splitting data \n",
    "from sklearn.linear_model import LinearRegression                  # training model \n",
    "from sklearn.metrics import r2_score , mean_squared_error          # assessment model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate object \n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitting : \n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform \n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or : \n",
    "scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a linear regression object :\n",
    "mulin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = [50,100,150,250,1000,2000,5000,8000,12000,21000]\n",
    "r2_score_seed = []\n",
    "RMSE_seed=[]\n",
    "\n",
    "\n",
    "for i in seed :\n",
    "    \n",
    "    # splitting the data into train and test set :\n",
    "    X_train , X_test , y_train , y_test = train_test_split(X , y , train_size  = 0.7 , random_state = i)\n",
    "    \n",
    "    # Creat and Fit a multiple linear regression model :\n",
    "    mulin = LinearRegression()\n",
    "    mulin.fit(X_train , y_train)\n",
    "    \n",
    "    # Make prediction on test set :\n",
    "    y_hat = mulin.predict(X_test)\n",
    "    \n",
    "    # model assessment : R^2 and RMSE :\n",
    "    r2_score_seed.append(r2_score(y_test,y_hat))\n",
    "    RMSE_seed.append(np.sqrt(mean_squared_error(y_test , y_hat)))\n",
    "\n",
    "# show results :\n",
    "\n",
    "print(\"The Coefficient of Determination of 10 models are : \\n\" , r2_score_seed )\n",
    "\n",
    "print(\"\\n \\n The Mean of The Coefficient of Determination of 10 models is :\" , np.array(r2_score_seed).mean())\n",
    "\n",
    "print(\"\\n \\n The Root Mean Square Error of 10 models are : \\n\", RMSE_seed )\n",
    "\n",
    "print(\"\\n \\n The Mean of The Root Mean Square Error of 10 models is : \" , np.array(RMSE_seed).mean())   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data , Training  and Assessment The Model With Different Test Sample Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = np.linspace(0.63,0.9,10)\n",
    "r2_score_size = []\n",
    "RMSE_size=[]\n",
    "\n",
    "\n",
    "for i in size :\n",
    "    \n",
    "    # splitting the data into train and test set :\n",
    "    X_train , X_test , y_train , y_test = train_test_split(X , y , train_size  = i , random_state = 4433)\n",
    "    \n",
    "    # Creat and Fit a multiple linear regression model :\n",
    "    mulin = LinearRegression()\n",
    "    mulin.fit(X_train , y_train)\n",
    "    \n",
    "    # Make prediction on test set :\n",
    "    y_hat = mulin.predict(X_test)\n",
    "    \n",
    "    # model assessment : R^2 and RMSE :\n",
    "    r2_score_size.append(r2_score(y_test,y_hat))\n",
    "    RMSE_size.append(np.sqrt(mean_squared_error(y_test , y_hat)))\n",
    "    \n",
    "# show results :\n",
    "\n",
    "print(\"The Coefficient of Determination of 10 models are : \\n\" , r2_score_size )\n",
    "\n",
    "print(\"\\n \\n The Mean of The Coefficient of Determination of 10 models is :\" , np.array(r2_score_size).mean())\n",
    "\n",
    "print(\"\\n \\n The Root Mean Square Error of 10 models are : \\n\", RMSE_size )\n",
    "\n",
    "print(\"\\n \\n The Mean of The Root Mean Square Error of 10 models is : \" , np.array(RMSE_size).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score class :\n",
    "from sklearn.model_selection import cross_val_score    \n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make r2_cv scorer : \n",
    "r2_score_cv = make_scorer(r2_score)\n",
    "\n",
    "# perform 10-fold Cross Validation : \n",
    "cv_10_fold = cross_val_score(mulin , X, y, cv = 10 , scoring = r2_score_cv)\n",
    "\n",
    "# show results : \n",
    "print(\"The Coefficient of Determination of 10 models are : \\n\" , cv_10_fold )\n",
    "\n",
    "print(\"\\n \\n The Mean of The Coefficient of Determination of 10 models is :\" , np.array(cv_10_fold).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make RMSE_cv scorer : \n",
    "RMSE_cv = make_scorer(mean_squared_error)\n",
    "\n",
    "# perform 10-fold Cross Validation : \n",
    "cv_10_fold = cross_val_score(mulin , X, y, cv = 10 , scoring = RMSE_cv)\n",
    "\n",
    "# show results : \n",
    "print(\"The Root Mean Square Error of 10 models are : \\n\", np.sqrt(np.array(cv_10_fold)))\n",
    "\n",
    "print(\"\\n \\n The Mean of The Root Mean Square Error of 10 models is : \" , np.sqrt(np.array(cv_10_fold)).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
